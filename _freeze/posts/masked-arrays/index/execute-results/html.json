{
  "hash": "cec3de045b970cc00185886d3d2cda5b",
  "result": {
    "markdown": "---\ntitle: \"Why masked arrays are useful for data science\"\nauthor: \"Carl Gaspar\"\ndate: \"2023-08-01\"\ncategories: [numpy, missing data, pairwise comparisons]\nimage: \"image.jpg\"\n---\n\nEver wanted to know why Numpy masked arrays are useful? Ever needed to compare lots of variables and struggled with missing data?\n\nComputations that are core to data science can be accelerated with the use of matrix operations. But real-world data has missing values and these can make matrix computations useless. Does that mean one must resort to inefficient for-loops when missing data is present?\n\nNo. Using Numpy masked arrays one can still reap the benefits of matrix operations whilst making full use of one's data.\n\nWhat kinds of things are we measuring here? We focus on pairwise comparisons among a large set of variables. The most familiar example is the **covariance matrix** but that is not all. \n\nThe approach described here generalizes to many cases where pairwise comparisons of some kind are to be calculated. I describe how to use masked arrays to calculate **percentage agreement** (and **Cohen's kappa coefficient**). That is what I happened to be working on recently.\n\nSo we'll start with covariance matrices. Then I'll show you a trick to quickly get matrices of percentage agreement (and **Cohen's kappa coefficient**) even with missing data.\n\n## Covariance matrices\n\nI will go over a simple example that will remind you what a covariance matrix is, and how it can be calculated using matrix multiplication.\n\nHere is some example data with 3 samples of 3 variables:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\n\nX = np.array([[-3, 3, 0],\n              [ 0, 0, 0],\n              [ 3,-3, 0]])\n\nnumber_samples, number_variables = X.shape\n```\n:::\n\n\nWe will get the covariance matrix using both Numpy and Pandas because there are some important differences. So here's the data in Pandas:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nX_ = pd.DataFrame(X, columns = [\"A\", \"B\", \"C\"], index = [\"sample \" + str(i) for i in range(1,4)])              \nprint(X_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          A  B  C\nsample 1 -3  3  0\nsample 2  0  0  0\nsample 3  3 -3  0\n```\n:::\n:::\n\n\nThe covariance matrix is a matrix showing the covariance between each pair of variables.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Using Numpy\n#   rowvar is False so that columns are variables\n#   bias is True to simplify our examples\nC = np.cov(X, rowvar=False, bias=True)\n\n# Using Pandas\n#   ddof is 0 (same as bias is True above)\nC_ = X_.cov(ddof=0)\nprint(C_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     A    B    C\nA  6.0 -6.0  0.0\nB -6.0  6.0  0.0\nC  0.0  0.0  0.0\n```\n:::\n:::\n\n\nAs you can see the covariance between variables `A` and `B` is $-6$.\nThe covariance between `C` and both `A` and `B` is $0$.\n\nCovariance is the expected product between 2 variables that are first centered at 0. We estimate it with the mean product. \n\nOur variables are already centered at zero:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nC_.sum(axis=0)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nA    0.0\nB    0.0\nC    0.0\ndtype: float64\n```\n:::\n:::\n\n\nSo we just need to:\n\n1. measure the sum of products between each pair of variables\n2. divide those products by 3 (the sample size)\n\nStep (1) can be done with matrix multiplication like this:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nproducts = np.matmul(X.transpose(), X)\n\nC_another_way = products / number_samples\n\nassert (C_another_way==C).all()\n```\n:::\n\n\nStep one (matrix multiplication) works really fast in Numpy. We used it here to get the covariance matrix but I'll show you how to also get a matrix of *percentage agreement*.\n\nBefore we get to that let's just make sure we know what's going on first.\n\n$C[0,1]$ is the covariance between the variables `A` and `B`.\n\n$products[0,1]$ is the sum of products between `A` and `B`.\n\nSo $products[0,1] = (-3\\times3) + (0\\times0) + (3\\times-3) = -18$\n\n$products[1,2]$ is the sum of products between `B` and `C`.\n\nAnd $products[0,1] = (3\\times0) + (0\\times0) + (-3\\times0) = 0$\n\n\n\n## Covariance matrices with missing data\n\n\n## Solution using masked arrays\n\n## Generalizing this approach to measure percentage agreement\n\n\n### End\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}